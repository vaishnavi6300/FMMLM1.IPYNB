{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishnavi6300/FMMLM1.IPYNB/blob/main/FMML_M1L1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6I1yI79fbLD"
      },
      "source": [
        "# Extracting features from data\n",
        "\n",
        "FMML Module 1, Lab 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OimBnfcpvcNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c0599e-8462-4f0b-c2d6-0e855175299b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install wikipedia nltk matplotlib plotly pandas\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import wikipedia\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from nltk.util import ngrams\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6hGhIGiy4GP"
      },
      "source": [
        "# Part 1: Features of text\n",
        "\n",
        "Computures can't understand text. They can only process numbers. So, the logical first step in any attempt to analyze text is to convert it into numbers. This process is called **feature extraction** or **vectorization**. In this lab, we will try some simple methods for feature extraction.\n",
        "\n",
        "First, let us download a 2 documents from Wikipedia in two different languages, English and French. We will then extract features from the text in these documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpUmCoEr2R3J"
      },
      "outputs": [],
      "source": [
        "topic1 = \"Giraffe\"\n",
        "topic2 = \"Elephant\"\n",
        "\n",
        "wikipedia.set_lang(\"en\")\n",
        "\n",
        "eng1 = wikipedia.page(topic1).content\n",
        "eng2 = wikipedia.page(topic2).content\n",
        "\n",
        "wikipedia.set_lang(\"fr\")\n",
        "\n",
        "fr1 = wikipedia.page(topic1).content\n",
        "fr2 = wikipedia.page(topic2).content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj7RlhMiO5kd"
      },
      "source": [
        "This is what the text looks like in English:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9D_8laDfupTt"
      },
      "outputs": [],
      "source": [
        "eng2[:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kdwJ30nupTt"
      },
      "source": [
        "This is what the text looks like in French:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW0G-t912UXZ"
      },
      "outputs": [],
      "source": [
        "fr2[:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZkmNJ7XO9xX"
      },
      "source": [
        "We need to clean this up a bit. Let us remove all the special characters and keep only 26 letters and space. Note that this will remove accented characters in French also. We are also removing all the numbers and spaces. So this is not an ideal solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5yf5P9pPI4t"
      },
      "outputs": [],
      "source": [
        "def cleanup(text):\n",
        "    text = text.lower()  # make it lowercase\n",
        "    text = re.sub(\n",
        "        r\"[^a-z\\s]\", \"\", text\n",
        "    )  # only keep characters in a-z range and whitespaces\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrOjC32fRuTK"
      },
      "outputs": [],
      "source": [
        "eng1 = cleanup(eng1)\n",
        "eng2 = cleanup(eng2)\n",
        "fr1 = cleanup(fr1)\n",
        "fr2 = cleanup(fr2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIdqvL2G-LqL"
      },
      "outputs": [],
      "source": [
        "eng2[:500]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fr2[:500]"
      ],
      "metadata": {
        "id": "oAnXWFaFLaZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXFTWwd0rk63"
      },
      "source": [
        "Now let us calculate the frequency of the character n-grams. N-grams are groups of characters of size n. A unigram is a single character and a bigram is a group of two characters and so on.\n",
        "\n",
        "Let us count the frequency of each character in a text and plot it in a histogram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3Lz3YUjN0L5"
      },
      "outputs": [],
      "source": [
        "def tuple2string(tup):\n",
        "    # convert a tuple of characters to a string\n",
        "    # ('t', 'h') - > 'th'\n",
        "    st = \"\"\n",
        "    for ii in tup:\n",
        "        st = st + ii\n",
        "    return st\n",
        "\n",
        "\n",
        "def key2string(keys):\n",
        "    # convert a tuple of tuples to a list of strings\n",
        "    # [('t', 'h'), ('h', 'e')] -> ['th', 'he']\n",
        "    # [('t')] - >['t']\n",
        "    return [tuple2string(i) for i in keys]\n",
        "\n",
        "\n",
        "def get_ngram_freq(ngram):\n",
        "    # get the frequency of ngrams\n",
        "    # sort the keys in alphabetic order\n",
        "    keys = key2string(ngram.keys())\n",
        "    values = list(ngram.values())\n",
        "\n",
        "    combined = zip(keys, values)\n",
        "    zipped_sorted = sorted(combined, key=lambda x: x[0])\n",
        "    keys, values = map(list, zip(*zipped_sorted))\n",
        "    return keys, values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHD62zbZcwAB"
      },
      "source": [
        "Let us compare the histograms of English pages and French pages. Can you spot a difference?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKcGRgH6b0KP"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "unigram_eng1 = Counter(ngrams(eng1, 1))\n",
        "keys, values = get_ngram_freq(unigram_eng1)\n",
        "axs[0].bar(keys, values)\n",
        "axs[0].set_title(\"English 1\")\n",
        "\n",
        "unigram_eng2 = Counter(ngrams(eng2, 1))\n",
        "keys, values = get_ngram_freq(unigram_eng2)\n",
        "axs[1].bar(keys, values)\n",
        "axs[1].set_title(\"English 2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDM_UhCL2QLt"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "unigram_fr1 = Counter(ngrams(fr1, 1))\n",
        "keys, values = get_ngram_freq(unigram_fr1)\n",
        "axs[0].bar(keys, values)\n",
        "axs[0].set_title(\"French 1\")\n",
        "\n",
        "unigram_fr2 = Counter(ngrams(fr2, 1))\n",
        "keys, values = get_ngram_freq(unigram_fr2)\n",
        "axs[1].bar(keys, values)\n",
        "axs[1].set_title(\"French 2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxgrdZLKdkAB"
      },
      "source": [
        "We can see that the unigrams for French and English are very similar. So this is not a good feature if we want to distinguish between English and French. Let us look at bigrams."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwPQbaTCupTu"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
        "bigram_eng1 = Counter(ngrams(eng1, 2))\n",
        "keys, values = get_ngram_freq(bigram_eng1)\n",
        "axs[0, 0].bar(keys, values)\n",
        "axs[0, 0].set_title(\"English 1\")\n",
        "\n",
        "bigram_eng2 = Counter(ngrams(eng2, 2))\n",
        "keys, values = get_ngram_freq(bigram_eng2)\n",
        "axs[0, 1].bar(keys, values)\n",
        "axs[0, 1].set_title(\"English 2\")\n",
        "\n",
        "bigram_fr1 = Counter(ngrams(fr1, 2))\n",
        "keys, values = get_ngram_freq(bigram_fr1)\n",
        "axs[1, 0].bar(keys, values)\n",
        "axs[1, 0].set_title(\"French 1\")\n",
        "\n",
        "bigram_fr2 = Counter(ngrams(fr2, 2))\n",
        "keys, values = get_ngram_freq(bigram_fr2)\n",
        "axs[1, 1].bar(keys, values)\n",
        "axs[1, 1].set_title(\"French 2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-egsHMIg5Rp"
      },
      "source": [
        "Another way to visualize bigrams is to use a 2-dimensional graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EaPJgtaVxZM"
      },
      "outputs": [],
      "source": [
        "def get_2D_ngram_freq(ngram):\n",
        "    freq = np.zeros((26, 26))\n",
        "    for ii in range(26):\n",
        "        for jj in range(26):\n",
        "            freq[ii, jj] = ngram[(chr(ord(\"a\") + ii), chr(ord(\"a\") + jj))]\n",
        "    return freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Hpu4zRVupTv"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
        "bigram_eng1_freq = get_2D_ngram_freq(bigram_eng1)\n",
        "fig.colorbar(axs[0, 0].imshow(bigram_eng1_freq, cmap=\"hot\"), ax=axs[0, 0])\n",
        "axs[0, 0].set_title(\"English 1\")\n",
        "\n",
        "bigram_eng2_freq = get_2D_ngram_freq(bigram_eng2)\n",
        "fig.colorbar(axs[0, 1].imshow(bigram_eng2_freq, cmap=\"hot\"), ax=axs[0, 1])\n",
        "axs[0, 1].set_title(\"English 2\")\n",
        "\n",
        "bigram_fr1_freq = get_2D_ngram_freq(bigram_fr1)\n",
        "fig.colorbar(axs[1, 0].imshow(bigram_fr1_freq, cmap=\"hot\"), ax=axs[1, 0])\n",
        "axs[1, 0].set_title(\"French 1\")\n",
        "\n",
        "bigram_fr2_freq = get_2D_ngram_freq(bigram_fr2)\n",
        "fig.colorbar(axs[1, 1].imshow(bigram_fr2_freq, cmap=\"hot\"), ax=axs[1, 1])\n",
        "axs[1, 1].set_title(\"French 2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGOEHcyGokD0"
      },
      "source": [
        "Let us look at the top 10 ngrams for each text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk2TkzTno8vb"
      },
      "outputs": [],
      "source": [
        "def ind2tup(ind):\n",
        "    ind = int(ind)\n",
        "    i = int(ind / 26)\n",
        "    j = int(ind % 26)\n",
        "    return (chr(ord(\"a\") + i), chr(ord(\"a\") + j))\n",
        "\n",
        "\n",
        "def ShowTopN(bifreq, n=10):\n",
        "    f = bifreq.flatten()\n",
        "    arg = np.argsort(-f)\n",
        "    for ii in range(n):\n",
        "        print(f\"{ind2tup(arg[ii])} : {f[arg[ii]]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HeWNh_q0QZ1"
      },
      "outputs": [],
      "source": [
        "print(\"\\nEnglish 1:\")\n",
        "ShowTopN(bigram_eng1_freq)\n",
        "\n",
        "print(\"\\nEnglish 2:\")\n",
        "ShowTopN(bigram_eng2_freq)\n",
        "\n",
        "print(\"\\nFrench 1:\")\n",
        "ShowTopN(bigram_fr1_freq)\n",
        "\n",
        "print(\"\\nFrench 2:\")\n",
        "ShowTopN(bigram_fr2_freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kDovOP4l98z"
      },
      "source": [
        "We observe that the bigrams are similar across different topics but different across languages. Thus, the bigram frequency is a good feature for distinguishing languages, but not for distinguishing topics.\n",
        "\n",
        "Thus, we were able to convert a many-dimensional input (the text) to 26 dimesions (unigrams) or 26*26 dimensions (bigrams).\n",
        "\n",
        "\n",
        "A few ways to explore:\n",
        "1. Try with different languages.\n",
        "2. The topics we used are quite similar, wikipedia articles of 'elephant' and 'giraffe'. What happens if we use very different topics? What if we use text from another source than Wikipedia?\n",
        "3. How can we use and visualize trigrams and higher n-grams?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDHuf6v0upTv"
      },
      "source": [
        "> Exercise: Try to extract trigrams and visualize the top 10 trigrams for each text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZJfjIHk-oHV"
      },
      "source": [
        "# Part 2: Written numbers\n",
        "\n",
        "We've seen how to extract features from text. Now let us see how to extract features from images. We will use the MNIST dataset which contains images of handwritten numbers. Each image is represented in a 28*28 array. Let us see if we can extract some simple features from these images which can help us distinguish between the digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNsLJSr6wGY0"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "# loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVNr144WAUZO"
      },
      "source": [
        "Extract a subset of the data for our experiment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3MN8ddxAASZ"
      },
      "outputs": [],
      "source": [
        "no1 = train_X[train_y == 1, :, :]\n",
        "no0 = train_X[train_y == 0, :, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePXCs0qyCLpc"
      },
      "source": [
        "Let us visualize a few images here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQeyZSh-Arpc"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 5, figsize=(15, 5))\n",
        "\n",
        "for ii in range(5):\n",
        "    axs[0, ii].imshow(no0[ii, :, :])\n",
        "\n",
        "for ii in range(5):\n",
        "    axs[1, ii].imshow(no1[ii, :, :])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g-Tg7EKDz96"
      },
      "source": [
        "Now, let us start with a simple feature: the sum of all pixels. Let's see how good this feature is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8SztDk7CyZc"
      },
      "outputs": [],
      "source": [
        "sum1 = np.sum(no1 > 0, (1, 2))  # threshold before adding up\n",
        "sum0 = np.sum(no0 > 0, (1, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oW3XCOCE7Zv"
      },
      "source": [
        "Let us visualize how good this feature is: (X-axis is mean, y-axis is the digit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8PIe8o_DPpU"
      },
      "outputs": [],
      "source": [
        "plt.hist(sum1, alpha=0.7)\n",
        "plt.hist(sum0, alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_hToEepFtl2"
      },
      "source": [
        "We can already see that this feature separates the two classes quite well.\n",
        "\n",
        "Let us look at another, more complicated feature. We will count the number black pixels that are surrounded on four sides by non-black pixels, or \"hole pixels\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwEnlm6RFFej"
      },
      "outputs": [],
      "source": [
        "def cumArray(img):\n",
        "    img2 = img.copy()\n",
        "    for ii in range(1, img2.shape[1]):\n",
        "        img2[ii, :] = (\n",
        "            img2[ii, :] + img2[ii - 1, :]\n",
        "        )  # for every row, add up all the rows above it.\n",
        "    img2 = img2 > 0\n",
        "    return img2\n",
        "\n",
        "\n",
        "def getHolePixels(img):\n",
        "    im1 = cumArray(img)\n",
        "    im2 = np.rot90(\n",
        "        cumArray(np.rot90(img)), 3\n",
        "    )  # rotate and cumulate it again for differnt direction\n",
        "    im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "    im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "    hull = (\n",
        "        im1 & im2 & im3 & im4\n",
        "    )  # this will create a binary image with all the holes filled in.\n",
        "    # remove the original digit to leave behind the holes\n",
        "    hole = hull & ~(img > 0)\n",
        "    return hole"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw3HjgnupUEI"
      },
      "source": [
        "Visualize a few. First row has the original zero number images and the second row has the hole pixels. Thrid row has original one number images and the last row has corresponding hole pixels which are non-existent, as expected."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_ids = [12, 236, 345, 435, 512]\n",
        "fig, axs = plt.subplots(4, 5, figsize=(15, 10))\n",
        "\n",
        "for ii, idx in enumerate(img_ids):\n",
        "    axs[0, ii].imshow(no0[idx, :, :])\n",
        "    axs[1, ii].imshow(getHolePixels(no0[idx, :, :]))\n",
        "    axs[2, ii].imshow(no1[idx, :, :])\n",
        "    axs[3, ii].imshow(getHolePixels(no1[idx, :, :]))"
      ],
      "metadata": {
        "id": "Ajzx6dkTwPst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS-4erNXtxMi"
      },
      "source": [
        "Now let us plot the number of hole pixels and see how this feature behaves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dpm1dRgsety8"
      },
      "outputs": [],
      "source": [
        "hole1 = np.array([getHolePixels(i).sum() for i in no1])\n",
        "hole0 = np.array([getHolePixels(i).sum() for i in no0])\n",
        "\n",
        "plt.hist(hole1, alpha=0.7)\n",
        "plt.hist(hole0, alpha=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UjCBHpJ31yq"
      },
      "source": [
        "This feature works even better to distinguish between one and zero.\n",
        "\n",
        "\n",
        "Now let us try the number of pixels in the 'hull' or the number with the holes filled in:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPtJ8eqolAOf"
      },
      "outputs": [],
      "source": [
        "def getHullPixels(img):\n",
        "    im1 = cumArray(img)\n",
        "    im2 = np.rot90(\n",
        "        cumArray(np.rot90(img)), 3\n",
        "    )  # rotate and cumulate it again for differnt direction\n",
        "    im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "    im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "    hull = (\n",
        "        im1 & im2 & im3 & im4\n",
        "    )  # this will create a binary image with all the holes filled in.\n",
        "    return hull"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_ids = [12, 236, 345, 435, 512]\n",
        "fig, axs = plt.subplots(4, 5, figsize=(15, 10))\n",
        "\n",
        "for ii, idx in enumerate(img_ids):\n",
        "    axs[0, ii].imshow(no0[idx, :, :])\n",
        "    axs[1, ii].imshow(getHullPixels(no0[idx, :, :]))\n",
        "    axs[2, ii].imshow(no1[idx, :, :])\n",
        "    axs[3, ii].imshow(getHullPixels(no1[idx, :, :]))"
      ],
      "metadata": {
        "id": "3fnBK7ImxtY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5rHal_HRWnE"
      },
      "source": [
        "Plotting the number of hull pixels versus the digit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTLzYZLTRQ_p"
      },
      "outputs": [],
      "source": [
        "hull1 = np.array([getHullPixels(i).sum() for i in no1])\n",
        "hull0 = np.array([getHullPixels(i).sum() for i in no0])\n",
        "\n",
        "plt.hist(hull1, alpha=0.7)\n",
        "plt.hist(hull0, alpha=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSzH26ElXNri"
      },
      "source": [
        "Let us try one more feature, where we look at the number of boundary pixels in each image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-2czBypXMwT"
      },
      "outputs": [],
      "source": [
        "def minus(a, b):\n",
        "    return a & ~b\n",
        "\n",
        "\n",
        "def getBoundaryPixels(img):\n",
        "    img = img.copy() > 0  # binarize the image\n",
        "    rshift = np.roll(img, 1, 1)\n",
        "    lshift = np.roll(img, -1, 1)\n",
        "    ushift = np.roll(img, -1, 0)\n",
        "    dshift = np.roll(img, 1, 0)\n",
        "    boundary = (\n",
        "        minus(img, rshift)\n",
        "        | minus(img, lshift)\n",
        "        | minus(img, ushift)\n",
        "        | minus(img, dshift)\n",
        "    )\n",
        "    return boundary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_ids = [12, 236, 345, 435, 512]\n",
        "fig, axs = plt.subplots(4, 5, figsize=(15, 10))\n",
        "\n",
        "for ii, idx in enumerate(img_ids):\n",
        "    axs[0, ii].imshow(no0[idx, :, :])\n",
        "    axs[1, ii].imshow(getBoundaryPixels(no0[idx, :, :]))\n",
        "    axs[2, ii].imshow(no1[idx, :, :])\n",
        "    axs[3, ii].imshow(getBoundaryPixels(no1[idx, :, :]))"
      ],
      "metadata": {
        "id": "kUOHZViDx5-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSsxsbCNXcNh"
      },
      "outputs": [],
      "source": [
        "bound1 = np.array([getBoundaryPixels(i).sum() for i in no1])\n",
        "bound0 = np.array([getBoundaryPixels(i).sum() for i in no0])\n",
        "\n",
        "plt.hist(bound1, alpha=0.7)\n",
        "plt.hist(bound0, alpha=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuP04Ao_R0Yz"
      },
      "source": [
        "What will happen if we plot two features together?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl7xWg-WRkAy"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "axs[0].scatter(sum0, hull0, alpha=0.1)\n",
        "axs[0].scatter(sum1, hull1, alpha=0.1)\n",
        "axs[0].set_xlabel(\"Sum\")\n",
        "axs[0].set_ylabel(\"Hull\")\n",
        "axs[0].legend([\"0\", \"1\"])\n",
        "\n",
        "axs[1].scatter(sum0, hole0, alpha=0.1)\n",
        "axs[1].scatter(sum1, hole1, alpha=0.1)\n",
        "axs[1].set_xlabel(\"Sum\")\n",
        "axs[1].set_ylabel(\"Hole\")\n",
        "axs[1].legend([\"0\", \"1\"])\n",
        "\n",
        "axs[2].scatter(bound0, hole0, alpha=0.1)\n",
        "axs[2].scatter(bound1, hole1, alpha=0.1)\n",
        "axs[2].set_xlabel(\"Boundary\")\n",
        "axs[2].set_ylabel(\"Hole\")\n",
        "axs[2].legend([\"0\", \"1\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JYLmKNFSIT-"
      },
      "source": [
        "Now let us try plotting 3 features together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOKEHIXFaWp_"
      },
      "outputs": [],
      "source": [
        "cl1 = [\"class 1\"] * len(sum1)\n",
        "cl0 = [\"class 0\"] * len(sum0)\n",
        "df = pd.DataFrame(\n",
        "    list(\n",
        "        zip(\n",
        "            np.concatenate((hole0, hole0)),\n",
        "            np.concatenate((sum1, sum0)),\n",
        "            np.concatenate((bound1, bound0)),\n",
        "            np.concatenate((cl1, cl0)),\n",
        "        )\n",
        "    ),\n",
        "    columns=[\"Hole\", \"Sum\", \"Boundary\", \"Class\"],\n",
        ")\n",
        "df.head()\n",
        "fig = px.scatter_3d(df, x=\"Hole\", y=\"Sum\", z=\"Boundary\",\n",
        "                    color=\"Class\", opacity=0.1)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paDGHlFSd5Fu"
      },
      "source": [
        "Feel free to explore the above graph with your mouse.\n",
        "\n",
        "\n",
        "We extracted four features from a 28*28 dimensional image.\n",
        "\n",
        "\n",
        "Some questions to explore:\n",
        "1. Which is the best combination of features?\n",
        "The \"best\" combination of features typically depends on the problem at hand and the data. The effectiveness of feature combinations is assessed by how well they capture the underlying patterns that differentiate between the target classes.\n",
        "\n",
        "To determine the best feature combination, you can use methods such as:\n",
        "\n",
        "Correlation analysis: Evaluate pairwise correlations between features to avoid redundancy.\n",
        "Feature importance methods: Algorithms like Random Forests, Gradient Boosting, or XGBoost can rank the importance of features.\n",
        "Dimensionality reduction: Techniques like PCA (Principal Component Analysis) or LDA (Linear Discriminant Analysis) can help you find optimal combinations of features by reducing multicollinearity and focusing on variance.\n",
        "Model-based selection: Use techniques like Recursive Feature Elimination (RFE), or forward/backward selection to test different feature sets for predictive power.\n",
        "2. How would you test or visualize four or more features?\n",
        "When working with high-dimensional data (more than three features), you can use several techniques to test or visualize the relationships between multiple features:\n",
        "\n",
        "Pairwise scatter plots: Use a scatterplot matrix or pairplot in libraries like seaborn to visualize relationships between each pair of features. For more than 4 features, pairplots can become too crowded.\n",
        "Principal Component Analysis (PCA): This technique reduces high-dimensional data to a lower-dimensional space (e.g., 2D or 3D) while preserving as much variance as possible. You can visualize the first two or three principal components.\n",
        "t-SNE or UMAP: These are non-linear dimensionality reduction techniques that preserve local structure and are often used to visualize high-dimensional data in 2D or 3D.\n",
        "Heatmaps of Correlation Matrices: Visualize the correlations between the features in a matrix format. This is helpful to identify which features are strongly correlated.\n",
        "Radial or Parallel Coordinate Plots: These plots can show high-dimensional data in a single image, helping to understand patterns across multiple features simultaneously.\n",
        "3. Can you come up with your own features?\n",
        "You can create new features based on domain knowledge or transformations of existing features. Some examples include:\n",
        "\n",
        "Interaction Features: Combine two or more features to form interaction terms, such as multiplying them together or taking their ratio. For instance, if you have features x and y, an interaction term could be x*y or x/y.\n",
        "Polynomial Features: Apply polynomial transformations to existing features (e.g., x^2, x^3) to capture non-linear relationships.\n",
        "Aggregated Features: Take statistical measures of existing features, such as the mean, median, max, or sum within a window or group.\n",
        "Domain-Specific Features: For example, if your features are related to time (e.g., date, hour), you could extract features such as day of the week, month, or holiday.\n",
        "Binned Features: Convert continuous features into categorical ones by binning them into intervals (e.g., age groups, income ranges).\n",
        "The effectiveness of these features depends on how well they represent the underlying patterns in the data. Feature engineering often involves testing various transformations and combinations and evaluating their impact on model performance.\n",
        "4. Will these features work for different classes other than 0 and 1?\n",
        "The features you create will likely work for multiple classes, but their effectiveness depends on the distribution and relationship between the features and the target variable.\n",
        "\n",
        "For multi-class classification, the key is that features should provide distinct boundaries for each class, not just for binary classification.\n",
        "Feature selection and dimensionality reduction techniques (e.g., PCA, LDA) can still be applied when you have more than two classes, but you need to ensure that the relationships among the different classes are well-represented in the features.\n",
        "For multi-class problems, consider using one-vs-all (OvA) or one-vs-one (OvO) approaches, which train a binary classifier for each class against all others (OvA) or between each pair of classes (OvO). In such cases, it's important that the features differentiate well across the different classes.\n",
        "5. What will happen if we take more that two classes at a time?\n",
        "When dealing with multi-class classification (more than two classes), several things change compared to binary classification:\n",
        "\n",
        "Model Output: The model typically produces a probability distribution over all classes. For example, a logistic regression model for binary classification outputs a probability for class 0 or 1, but for multi-class classification, it outputs a probability for each class, and you pick the class with the highest probability.\n",
        "Evaluation Metrics: Metrics like accuracy, precision, recall, and F1-score can be adapted for multi-class problems. You can compute these metrics in several ways:\n",
        "Macro-average: Average the metric across all classes.\n",
        "Micro-average: Aggregate the contributions of all classes before calculating the metric.\n",
        "Weighted-average: Average the metric, but weight it by the number of instances of each class.\n",
        "Confusion Matrix: The confusion matrix for multi-class classification will have more rows and columns, representing the different classes. It shows the true positive, false positive, false negative, and true negative counts for each class.\n",
        "Class Imbalance: With multiple classes, some classes may be underrepresented compared to others. This can affect model performance, and you might need to use techniques like oversampling, undersampling, or class weighting.\n",
        "Multiclass Classifiers: Algorithms like Random Forests, Support Vector Machines (SVM), and Neural Networks are directly extendable to multi-class classification. However, some algorithms like Logistic Regression need to be adapted (e.g., using one-vs-all or one-vs-one strategies).\n",
        "The key challenge in multi-class classification is that the decision boundaries become more complex as the number of classes increases. More sophisticated techniques, such as multi-class loss functions (e.g., categorical cross-entropy), and careful analysis of class separability, are needed to handle this complexity.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Exercise: Remember we took a subset of only the first two numbers in MNIST? Include 5 or more numbers now and try to visualise which feature works best when multiple numbers are involved. Brownie points if you use all numbers :)"
      ],
      "metadata": {
        "id": "vHE2yqmpzOXs"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}