{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishnavi6300/FMMLM1.IPYNB/blob/main/FMML_M1L4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU9LZjQxiQT2"
      },
      "source": [
        "# Transforming data using linear algebra\n",
        "\n",
        "FMML Module 1, Lab 4\n",
        "\n",
        "Matrix transformations are at the heart of many machine learning algorithms. In this lab, we'll visualize the effect of some simple transformations on a unit square and then visualize it using the MNIST dataset. We also see what data normalization means and how it can help in improving the accuracy of machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBe4ZA32UTbv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7mqG-dafVpya"
      },
      "outputs": [],
      "source": [
        "# You don't need to understand these functions\n",
        "\n",
        "\n",
        "def plotGrid(transform, unit, linestyle=\":\", fig=None, ax=None):\n",
        "    lim1 = -100\n",
        "    lim2 = 100\n",
        "\n",
        "    def mat2xy(start, end):\n",
        "        if len(start.shape) == 1:\n",
        "            start = np.expand_dims(start, 0)\n",
        "            end = np.expand_dims(end, 0)\n",
        "        nan = np.ones(len(start)) * np.nan\n",
        "        x = np.stack((start[:, 0], end[:, 0], nan)).T.reshape(-1)\n",
        "        y = np.stack((start[:, 1], end[:, 1], nan)).T.reshape(-1)\n",
        "        return x, y\n",
        "\n",
        "    def parallellines(axis, addend, lines, unit):\n",
        "        addend = np.repeat(np.expand_dims(addend, 0), lines * 2, 0)\n",
        "        unit = np.expand_dims(np.arange(-lines, lines) * unit, 1)\n",
        "        unit = unit - lines\n",
        "        addend = addend * unit\n",
        "        lines = np.expand_dims(axis, 0) + addend\n",
        "        return np.concatenate((lines, lines * -1))\n",
        "\n",
        "    if fig is None:\n",
        "        fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    transform = transform.astype(float)\n",
        "    xaxis = transform[0]\n",
        "    yaxis = transform[1]\n",
        "\n",
        "    # plot lines parallel to the x axis\n",
        "    lines1 = parallellines(xaxis * lim1, yaxis, 100, unit)\n",
        "    lines2 = parallellines(xaxis * lim2, yaxis, 100, unit)\n",
        "    x, y = mat2xy(lines1, lines2)\n",
        "    plt.plot(x, y, linestyle + \"k\", linewidth=0.5)\n",
        "    # plot x axis\n",
        "    x, y = mat2xy(xaxis * lim1, xaxis * lim2)\n",
        "    plt.plot(x, y, linestyle, color=\"#440077\")\n",
        "\n",
        "    # plot  lines parallel to the y axis\n",
        "    lines1 = parallellines(yaxis * lim1, xaxis, 100, unit)\n",
        "    lines2 = parallellines(yaxis * lim2, xaxis, 100, unit)\n",
        "    x, y = mat2xy(lines1, lines2)\n",
        "    plt.plot(x, y, linestyle + \"k\", linewidth=0.5)\n",
        "    # plot y axis\n",
        "    x, y = mat2xy(yaxis * lim1, yaxis * lim2)\n",
        "    plt.plot(x, y, linestyle, color=\"#aa5500\")\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "def plotData(X, y, xlabel=\"hole\", ylabel=\"bound\", fig=None, ax=None):\n",
        "    if fig is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    for ii in range(nclasses):\n",
        "        plt.scatter(X[y == ii, 0], X[y == ii, 1])\n",
        "    plt.legend([str(i) for i in range(nclasses)])\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    lim2 = X.max()\n",
        "    lim1 = X.min()\n",
        "    return fig, ax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d5dmEXxaktp"
      },
      "source": [
        "## Matrix transformations on data\n",
        "\n",
        "Note: This lab involves a lot of matrix operations. If you are not familiar with them, please go through the resources given in class before proceeding. You can also review Khan Academy's excellent linear algebra [resources](https://www.khanacademy.org/math/linear-algebra/matrix-transformations).\n",
        "\n",
        "A 2D coordinate system is defined by its basis vectors, i and j. Any point in this 2D space can be represented as a linear combination of these basis vectors. For example, the point (a,b) can be represented as:\n",
        "\n",
        "$$\\begin{equation}\n",
        "\\left\\{  \\begin{aligned}a \\\\ b \\end{aligned} \\right\\} = a\\left\\{  \\begin{aligned}1 \\\\ 0 \\end{aligned} \\right\\} + b\\left\\{  \\begin{aligned}0 \\\\ 1 \\end{aligned} \\right\\} = a\\hat{i} + b\\hat{j}\n",
        "\\end{equation}$$\n",
        "\n",
        "A matrix can be used to perform a linear transformation on the basis vectors. The new basis vectors $\\hat{i}$ and $\\hat{j}$ are given by the product of the matrix and the basis vectors of the standard coordinate system.\n",
        "\n",
        "In the standard coordinate system (Let us call it T0), the basis vectors are\n",
        "\n",
        "$$\\begin{equation}\n",
        "i = \\left\\{  \\begin{aligned}1 \\\\ 0 \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "and\n",
        "$$\\begin{equation} j = \\left\\{ \\begin{aligned} 0 \\\\ 1\\end{aligned} \\right\\} \\end{equation}$$\n",
        "\n",
        "We can use any two vectors as basis vectors for a new coordinate system as long as they are not colinear. For example, let us call this new coordinate system T1:\n",
        "\n",
        "$$\\begin{equation}\n",
        "i = \\left\\{  \\begin{aligned}1 \\\\ -1 \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "and\n",
        "$$\\begin{equation} j = \\left\\{ \\begin{aligned} 0 \\\\ 2 \\end{aligned} \\right\\} \\end{equation}$$\n",
        "\n",
        "Suppose we have a point [a,b] in the T1 coordinate system. Its representation in the standard system T0 can be obtained by the following matrix multiplication:\n",
        "\n",
        "$$ \\begin{equation}\n",
        "\\left\\{  \\begin{aligned}a' \\\\ b' \\end{aligned} \\right\\} =\n",
        "\\left\\{  \\begin{aligned}&1 & 0 \\\\ -&1 & 2 \\end{aligned} \\right\\}\n",
        "\\left\\{  \\begin{aligned}a \\\\ b \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "where the columns of the matrix are the basis vectors of T1.\n",
        "\n",
        "\n",
        "Let us see this in action:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8SCFKqfbM-l"
      },
      "outputs": [],
      "source": [
        "T0 = np.array([[1, 0], [0, 1]])\n",
        "T1 = np.array([[1, 0], [-1, 2]])\n",
        "\n",
        "data1 = np.array([5, 4])  # the data in T1 coordinate system\n",
        "data0 = np.matmul(T1, data1)  # the data in T0 coordinate system\n",
        "\n",
        "print(\"Data in T0 = \", data0)\n",
        "print(\"Data in T1 = \", data1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIfEWZ1RQeve"
      },
      "source": [
        "We can visualize this below. T0 is shown with dotted lines and T1 is shown with solid lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSuTaeSDQoYK"
      },
      "outputs": [],
      "source": [
        "fig, ax = plotGrid(T1.T, 1, \"-\")\n",
        "plotGrid(T0.T, 1, fig=fig, ax=ax)\n",
        "\n",
        "plt.scatter(data0[0], data0[1])\n",
        "ax.set_xlim(-10, 10)\n",
        "ax.set_ylim(-10, 10)\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUb3oYWIgdya"
      },
      "source": [
        "Look at the coordinates of the blue dot. In T0 (dotted lines), the position is [5,3] where it is [5,4] in T1. Feel free to experiment with different data points and coordinate systems.\n",
        "\n",
        "Remember that we can achieve the same thing by post-multiplying the transpose of the transformation matrix to the data. This will come in handy when transforming multiple data points at once:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD4pqOMndf-4"
      },
      "outputs": [],
      "source": [
        "data0_a = np.matmul(T1, data1)\n",
        "data0_b = np.matmul(data1, T1.T)\n",
        "print(data0_a)\n",
        "print(data0_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Kui3dSESPm"
      },
      "source": [
        "Why is transforming data useful? Data transformations cause the distance between data points to change. This will affect distance-based algorithms such as nearest neighbour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE0NbpYIC9ou"
      },
      "outputs": [],
      "source": [
        "# let us define 3 points in T1\n",
        "A1 = np.array([3, 3])\n",
        "B1 = np.array([2, -5])\n",
        "C1 = np.array([1, -1])\n",
        "\n",
        "# the corresponding points in T0:\n",
        "A0 = np.matmul(T1, A1)\n",
        "B0 = np.matmul(T1, B1)\n",
        "C0 = np.matmul(T1, C1)\n",
        "\n",
        "\n",
        "def dist(a, b):\n",
        "    # function to calculate Euclidean distance between two points\n",
        "    diff = a - b\n",
        "    sq = diff * diff\n",
        "    return np.sqrt(sq.sum())\n",
        "\n",
        "\n",
        "# distance between the points in T1\n",
        "print(\"Distance between A and B in T1 = \", dist(A1, B1))\n",
        "print(\"Distance between B and C in T1 = \", dist(B1, C1))\n",
        "print(\"Distance between A and C in T1 = \", dist(A1, C1))\n",
        "\n",
        "print(\"\")\n",
        "# distnace between the points in T0\n",
        "print(\"Distance between A and B in T0 = \", dist(A0, B0))\n",
        "print(\"Distance between B and C in T0 = \", dist(B0, C0))\n",
        "print(\"Distance between A and C in T0 = \", dist(A0, C0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE95JMniUtDm"
      },
      "source": [
        "We see that in T1, B and C are the closest whereas in T0, A and C are the closest. These kinds of changes will affect the predictions returned by the nearest neighbour algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFbpTSBdV29C"
      },
      "source": [
        "## Transformations on MNIST\n",
        "\n",
        "Let us experiment with a subset of the MNIST dataset. We will extract two features from the database for our experiment. We will then transform the data using a transformation matrix and visualize the data in the new coordinate system. We will also see how normalization can help in improving the accuracy of the model. We will reuse previous labs code for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "22ayl0sViF5-"
      },
      "outputs": [],
      "source": [
        "def NN1(traindata, trainlabel, query):\n",
        "    \"\"\"\n",
        "    This function takes in the training data, training labels and a query point\n",
        "    and returns the predicted label for the query point using the nearest neighbour algorithm\n",
        "\n",
        "    traindata: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    trainlabel: numpy array of shape (n,) where n is the number of samples\n",
        "    query: numpy array of shape (d,) where d is the number of features\n",
        "\n",
        "    returns: the predicted label for the query point which is the label of the training data which is closest to the query point\n",
        "    \"\"\"\n",
        "    diff = (\n",
        "        traindata - query\n",
        "    )  # find the difference between features. Numpy automatically takes care of the size here\n",
        "    sq = diff * diff  # square the differences\n",
        "    dist = sq.sum(1)  # add up the squares\n",
        "    label = trainlabel[np.argmin(dist)]\n",
        "    return label\n",
        "\n",
        "\n",
        "def NN(traindata, trainlabel, testdata):\n",
        "    \"\"\"\n",
        "    This function takes in the training data, training labels and test data\n",
        "    and returns the predicted labels for the test data using the nearest neighbour algorithm\n",
        "\n",
        "    traindata: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    trainlabel: numpy array of shape (n,) where n is the number of samples\n",
        "    testdata: numpy array of shape (m,d) where m is the number of test samples and d is the number of features\n",
        "\n",
        "    returns: the predicted labels for the test data which is the label of the training data which is closest to each test point\n",
        "    \"\"\"\n",
        "    predlabel = np.array([NN1(traindata, trainlabel, i) for i in testdata])\n",
        "    return predlabel\n",
        "\n",
        "\n",
        "def Accuracy(gtlabel, predlabel):\n",
        "    \"\"\"\n",
        "    This function takes in the ground-truth labels and predicted labels\n",
        "    and returns the accuracy of the classifier\n",
        "\n",
        "    gtlabel: numpy array of shape (n,) where n is the number of samples\n",
        "    predlabel: numpy array of shape (n,) where n is the number of samples\n",
        "\n",
        "    returns: the accuracy of the classifier which is the number of correct predictions divided by the total number of predictions\n",
        "    \"\"\"\n",
        "    assert len(gtlabel) == len(\n",
        "        predlabel\n",
        "    ), \"Length of the ground-truth labels and predicted labels should be the same\"\n",
        "    correct = (\n",
        "        gtlabel == predlabel\n",
        "    ).sum()  # count the number of times the groundtruth label is equal to the predicted label.\n",
        "    return correct / len(gtlabel)\n",
        "\n",
        "\n",
        "def cumArray(img):\n",
        "    img2 = img.copy()\n",
        "    for ii in range(1, img2.shape[1]):\n",
        "        # for every row, add up all the rows above it.\n",
        "        img2[ii, :] = img2[ii, :] + img2[ii - 1, :]\n",
        "    img2 = img2 > 0\n",
        "    return img2\n",
        "\n",
        "\n",
        "def getHolePixels(img):\n",
        "    \"\"\"\n",
        "    This function takes in a binary image and returns the pixels that are holes in the image\n",
        "\n",
        "    img: numpy array of shape (n,m) where n is the height of the image and m is the width of the image\n",
        "\n",
        "    returns: a binary image of the same shape as the input image where the holes are filled in\n",
        "    \"\"\"\n",
        "    im1 = cumArray(img)\n",
        "    # rotate and cumulate it again for differnt direction\n",
        "    im2 = np.rot90(cumArray(np.rot90(img)), 3)\n",
        "    im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "    im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "    # this will create a binary image with all the holes filled in.\n",
        "    hull = im1 & im2 & im3 & im4\n",
        "    # remove the original digit to leave behind the holes\n",
        "    hole = hull & ~(img > 0)\n",
        "    return hole\n",
        "\n",
        "\n",
        "def getHullPixels(img):\n",
        "    \"\"\"\n",
        "    This function takes in a binary image and returns the pixels that are the convex hull of the image\n",
        "\n",
        "    img: numpy array of shape (n,m) where n is the height of the image and m is the width of the image\n",
        "\n",
        "    returns: a binary image of the same shape as the input image where the convex hull is filled in\n",
        "    \"\"\"\n",
        "    im1 = cumArray(img)\n",
        "    # rotate and cumulate it again for differnt direction\n",
        "    im2 = np.rot90(cumArray(np.rot90(img)), 3)\n",
        "    im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "    im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "    # this will create a binary image with all the holes filled in.\n",
        "    hull = im1 & im2 & im3 & im4\n",
        "    return hull\n",
        "\n",
        "\n",
        "def minus(a, b):\n",
        "    \"\"\"\n",
        "    This function takes in two binary images and returns the difference between the two images\n",
        "    \"\"\"\n",
        "    return a & ~b\n",
        "\n",
        "\n",
        "def getBoundaryPixels(img):\n",
        "    \"\"\"\n",
        "    This function takes in a binary image and returns the pixels that are the boundary of the image\n",
        "\n",
        "    img: numpy array of shape (n,m) where n is the height of the image and m is the width of the image\n",
        "\n",
        "    returns: a binary image of the same shape as the input image where the boundary is filled in\n",
        "    \"\"\"\n",
        "    img = img.copy() > 0  # binarize the image\n",
        "    rshift = np.roll(img, 1, 1)\n",
        "    lshift = np.roll(img, -1, 1)\n",
        "    ushift = np.roll(img, -1, 0)\n",
        "    dshift = np.roll(img, 1, 0)\n",
        "    boundary = (\n",
        "        minus(img, rshift)\n",
        "        | minus(img, lshift)\n",
        "        | minus(img, ushift)\n",
        "        | minus(img, dshift)\n",
        "    )\n",
        "    return boundary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHz5BVmLUjzb"
      },
      "outputs": [],
      "source": [
        "# loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "train_X = train_X / 255\n",
        "test_X = test_X / 255\n",
        "\n",
        "nclasses = 4\n",
        "\n",
        "# get only for the first 4 classes\n",
        "train_X = train_X[train_y < nclasses]\n",
        "train_y = train_y[train_y < nclasses]\n",
        "test_X = test_X[test_y < nclasses]\n",
        "test_y = test_y[test_y < nclasses]\n",
        "\n",
        "# We are only taking a subset of the training set\n",
        "train_X = train_X[::100].copy()\n",
        "train_y = train_y[::100].copy()  # do the same to the labels\n",
        "\n",
        "# taking a subset of the test set. This code takes every 500th sample\n",
        "test_X = test_X[::100].copy()\n",
        "test_y = test_y[::100].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvavjmfvH515"
      },
      "outputs": [],
      "source": [
        "# feature extraction\n",
        "train_hole = np.array([getHolePixels(i).sum() for i in train_X])\n",
        "test_hole = np.array([getHolePixels(i).sum() for i in test_X])\n",
        "train_bound = np.array([getBoundaryPixels(i).sum() for i in train_X])\n",
        "test_bound = np.array([getBoundaryPixels(i).sum() for i in test_X])\n",
        "# train_hull = np.array([getHullPixels(i).sum() for i in train_X])\n",
        "# test_hull = np.array([getHullPixels(i).sum() for i in test_X])\n",
        "# train_sum = np.sum(train_X, (1, 2)) / (28 * 28)\n",
        "# test_sum = np.sum(test_X, (1, 2)) / (28 * 28)\n",
        "\n",
        "# create the train and test set by combining the appropriate features\n",
        "train_feats = np.vstack(\n",
        "    (train_hole, train_bound)).transpose()\n",
        "test_feats = np.vstack(\n",
        "    (test_hole, test_bound)).transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7qGVrlnQCUy"
      },
      "source": [
        "Let us plot the samples and see what they look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saRzHfi9QAGd"
      },
      "outputs": [],
      "source": [
        "# fix limits of x and y axis so that we can see what is going on\n",
        "xlim = [-100, 300]\n",
        "ylim = [-100, 300]\n",
        "fig, ax = plotData(train_feats, train_y)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCb4DikQP1ck"
      },
      "source": [
        "Check the baseline accuracy on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxVr6bd9PzlI"
      },
      "outputs": [],
      "source": [
        "test_pred = NN(train_feats, train_y, test_feats)\n",
        "acc = Accuracy(test_y, test_pred)\n",
        "print(\"Baseline accuracy:\", acc*100, \"%\", \"for\", nclasses, \"classes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl8Noo8pZRek"
      },
      "source": [
        "Let us try transforming the features and checking their accuracy. The intuition to using the transformation matrix is to find the basis vectors of the dataset and transform the data to a new coordinate system where the basis vectors are orthogonal. This will help in reducing the redundancy in the data and improve the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dUPWRsEZKwo"
      },
      "outputs": [],
      "source": [
        "transform = np.array([[0.5, -0.5], [0, 2.5]])\n",
        "print(transform)\n",
        "\n",
        "train_feats_t = np.matmul(train_feats, transform)\n",
        "# whatever transform we are applying to the training set should be applied to the test set also\n",
        "test_feats_t = np.matmul(test_feats, transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRH4VckHZaWv"
      },
      "outputs": [],
      "source": [
        "fig, ax = plotData(train_feats_t, train_y)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9fknczfZdYF"
      },
      "outputs": [],
      "source": [
        "test_pred = NN(train_feats_t, train_y, test_feats_t)\n",
        "acc = Accuracy(test_y, test_pred)\n",
        "print(\"Baseline accuracy:\", acc*100, \"%\", \"for\", nclasses, \"classes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFBQlAnNZ3on"
      },
      "source": [
        "## Questions:\n",
        "1. Experiment with different transformation matrices and check the accuracy\n",
        "In image processing and machine learning, transformation matrices can be used to perform various geometric operations like rotation, scaling, shearing, and translation. These transformations can help augment the dataset by altering the original data, making the model more robust. To experiment with transformation matrices, we can apply them to image data or even multi-dimensional numerical data and check the resulting accuracy on a given task.\n",
        "\n",
        "The general transformation matrix for 2D geometric operations is of the form:\n",
        "\n",
        "𝑇\n",
        "=\n",
        "[\n",
        "𝑎\n",
        "𝑏\n",
        "𝑐\n",
        "𝑑\n",
        "]\n",
        "T=[\n",
        "a\n",
        "c\n",
        "​\n",
        "  \n",
        "b\n",
        "d\n",
        "​\n",
        " ]\n",
        "Where the parameters\n",
        "𝑎\n",
        ",\n",
        "𝑏\n",
        ",\n",
        "𝑐\n",
        ",\n",
        "𝑑\n",
        "a,b,c,d correspond to scaling, rotation, and shearing operations. For 3D transformations, the matrices become more complex.\n",
        "\n",
        "Key Transformation Matrices:\n",
        "Rotation Matrix (2D):\n",
        "For rotating an image by an angle θ:\n",
        "\n",
        "[\n",
        "cos\n",
        "⁡\n",
        "𝜃\n",
        "−\n",
        "sin\n",
        "⁡\n",
        "𝜃\n",
        "sin\n",
        "⁡\n",
        "𝜃\n",
        "cos\n",
        "⁡\n",
        "𝜃\n",
        "]\n",
        "[\n",
        "cosθ\n",
        "sinθ\n",
        "​\n",
        "  \n",
        "−sinθ\n",
        "cosθ\n",
        "​\n",
        " ]\n",
        "This matrix rotates the image counter-clockwise by the given angle θ.\n",
        "\n",
        "Shearing Matrix (2D):\n",
        "Shear can stretch the image along one axis while leaving the other axis unchanged:\n",
        "\n",
        "Horizontal shear:\n",
        "[\n",
        "1\n",
        "𝑘\n",
        "0\n",
        "1\n",
        "]\n",
        "[\n",
        "1\n",
        "0\n",
        "​\n",
        "  \n",
        "k\n",
        "1\n",
        "​\n",
        " ]\n",
        "Vertical shear:\n",
        "[\n",
        "1\n",
        "0\n",
        "𝑘\n",
        "1\n",
        "]\n",
        "[\n",
        "1\n",
        "k\n",
        "​\n",
        "  \n",
        "0\n",
        "1\n",
        "​\n",
        " ]\n",
        "Where k is the shear factor.\n",
        "Scaling Matrix (2D):\n",
        "To scale an image by a factor s_x in the x-direction and s_y in the y-direction:\n",
        "\n",
        "[\n",
        "𝑠\n",
        "𝑥\n",
        "0\n",
        "0\n",
        "𝑠\n",
        "𝑦\n",
        "]\n",
        "[\n",
        "s\n",
        "x\n",
        "​\n",
        "\n",
        "0\n",
        "​\n",
        "  \n",
        "0\n",
        "s\n",
        "y\n",
        "​\n",
        "\n",
        "​\n",
        " ]\n",
        "Translation Matrix (2D): For translating (shifting) the image by distances dx and dy:\n",
        "\n",
        "[\n",
        "1\n",
        "0\n",
        "𝑑\n",
        "𝑥\n",
        "0\n",
        "1\n",
        "𝑑\n",
        "𝑦\n",
        "0\n",
        "0\n",
        "1\n",
        "]\n",
        "​\n",
        "  \n",
        "1\n",
        "0\n",
        "0\n",
        "​\n",
        "  \n",
        "0\n",
        "1\n",
        "0\n",
        "​\n",
        "  \n",
        "dx\n",
        "dy\n",
        "1\n",
        "​\n",
        "  \n",
        "​\n",
        "\n",
        "This translation matrix shifts the image along the x and y axes by dx and dy, respectively.\n",
        "\n",
        "How to Experiment with Transformation Matrices and Accuracy\n",
        "We can use these transformations to augment the data and then measure the impact on model performance. Here's the general process:\n",
        "\n",
        "Define Transformations: Set up different combinations of transformations like rotation, shear, scale, and translation.\n",
        "Apply to Dataset: Apply these transformations to the images in the training set.\n",
        "Train and Evaluate: Train a model on the transformed dataset and evaluate its performance (accuracy).\n",
        "Compare Performance: Compare the accuracy of models trained on original vs. transformed data.\n",
        "2. Will the same transform used for these two features also work for other features?\n",
        "The transformations you use may or may not work equally well for different features depending on the type of data you're dealing with. Here's a breakdown of how different features might be impacted:\n",
        "\n",
        "Image Data:\n",
        "Rotation and Translation: For objects or scenes in images, rotation and translation can help generalize the model and handle real-world variations. These transformations typically work well for visual features (e.g., object classification).\n",
        "Shearing and Scaling: These transformations might work well for images with distorted objects or those where proportions need to be handled carefully. Shearing could distort the shape of objects, so it might not be effective for datasets where object proportions are important (e.g., face recognition).\n",
        "Numerical Data:\n",
        "If you're dealing with non-image features (e.g., sensor data, time series), applying shear, rotation, and translation transformations may not make sense. These kinds of transformations are spatially oriented and typically don’t preserve the relationships in time series or tabular data.\n",
        "For tabular data with numerical features, you might consider other types of transformations like normalization, standardization, or log transformations rather than geometric transformations.\n",
        "6. Will the Same Transformation Work for Other Features?\n",
        "In general, the same transformation matrix will not always work for different types of features, especially when you switch from image data to tabular data or time-series data:\n",
        "\n",
        "For image data: Transformations like rotation, shearing, scaling, and flipping typically work well for spatial features.\n",
        "For tabular or numerical data: Geometric transformations (such as rotation or shearing) would not make sense. Instead, you might use statistical transformations (like normalization, scaling, etc.).\n",
        "For time-series data: Techniques like time-shifting, sliding windows, or data augmentation using synthetic sequences would be more effective than traditional geometric transformations.\n",
        "Conclusion\n",
        "Experimenting with Transformation Matrices: Applying transformations like rotation, shearing, scaling, and translation can be powerful tools for data augmentation, especially in image classification tasks.\n",
        "Effectiveness for Different Features: The same transformations might not work for all features. For image data, geometric transformations are effective, but for other data types (e.g., tabular, time-series), you would need to tailor the transformations to the specific domain.\n",
        "Optimizing Transformations for Accuracy: By experimenting with different transformation matrices and augmentations, you can improve your model's generalization, which should ideally improve its performance and robustness to new, unseen data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXCnbDsVH516"
      },
      "source": [
        "> Exercise: Is it possible that adding all 4 features at a time is not the best strategy? Can you think of a better combination of features that can help in improving the accuracy of the model? Maybe you can try adding 2 features at a time and see if that helps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36TOA47xak20"
      },
      "source": [
        "# Data normalization\n",
        "\n",
        "Sometimes the features of our data have vastly different scales. This will cause the learning algorithm to give more importance to certain features, reducing its performance. Data normalization is a method in which we transform the features so that they have similar scales.\n",
        "\n",
        "Three commonly used feature scaling techniques are rescaling, mean normalization and z-score normalization. Here, we will talk about the simplest one: rescaling.\n",
        "\n",
        "$$\\begin{equation}\n",
        "x' = \\frac {x -min(x)} { max(x) - min(x)}\n",
        "\\end{equation}$$\n",
        "\n",
        "\n",
        "\n",
        "For more information, see [this page](https://towardsdatascience.com/data-normalization-in-machine-learning-395fdec69d02)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni19QKDLZzeo"
      },
      "outputs": [],
      "source": [
        "def rescale(data):\n",
        "    return (data - data.min()) / (data.max() - data.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k83ZMtKeZrQ"
      },
      "source": [
        "We have to apply the rescaling to each feature individually. Also remember to apply the same transform we are using on the train set to the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JLOPwhvehpR"
      },
      "outputs": [],
      "source": [
        "train_feats_rescaled_x = rescale(train_feats[:, 0])\n",
        "train_feats_rescaled_y = rescale(train_feats[:, 1])\n",
        "train_feats_rescaled = np.stack((train_feats_rescaled_x, train_feats_rescaled_y), 1)\n",
        "\n",
        "test_feats_rescaled_x = rescale(test_feats[:, 0])\n",
        "test_feats_rescaled_y = rescale(test_feats[:, 1])\n",
        "test_feats_rescaled = np.stack((test_feats_rescaled_x, test_feats_rescaled_y), 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaZVy9vxfKwX"
      },
      "source": [
        "Let us plot the rescaled features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXyatpwZevOH"
      },
      "outputs": [],
      "source": [
        "fig, ax = plotData(train_feats_rescaled, train_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjBgxE6zglsL"
      },
      "source": [
        "This type of rescaling makes all the features between 0 and 1.\n",
        "\n",
        "Let us calculate the accuracy obtained by this transform:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKQnsj-KgNZc"
      },
      "outputs": [],
      "source": [
        "test_pred = NN(train_feats_rescaled, train_y, test_feats_rescaled)\n",
        "acc = Accuracy(test_y, test_pred)\n",
        "print(\"Accuracy after transform:\", acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qYX90Gqg-jO"
      },
      "source": [
        "All 2D linear transformations can be repreented by a transformation matrix. So what is the matrix associated with the rescaling function? Actually, we cannot represent rescaling with a matrix multiplication, because it is not a linear transform. Rescaling involves shifting the origin of the data, which is not allowed under linear transformations.\n",
        "\n",
        "We can represent rescaling as a matrix multiplication followed by a vector addition. Let our first feature vector be called X and second feature vector be called Y. Suppose we want to rescale a data point [a,b]\n",
        "\n",
        "$$ \\begin{equation}\n",
        " \\left\\{  \\begin{aligned}a' \\\\ b' \\end{aligned} \\right\\} =\n",
        " \\left\\{  \\begin{aligned} \\frac{a - min(X)}{max(X) - min(X)} \\\\ \\frac{b - min(Y)}{max(Y) - min(Y)} \\end{aligned} \\right\\} =\n",
        " \\left\\{  \\begin{aligned}&\\frac{1}{max(X)-min(X)} &0\\\\ &0 &\\frac{1}{max(Y)-min(Y)} \\end{aligned}\n",
        " \\right\\}\\left\\{  \\begin{aligned}a \\\\ b \\end{aligned} \\right\\} +\n",
        " \\left\\{  \\begin{aligned} \\frac{ -min(X)}{max(X) - min(X)} \\\\ \\frac{-min(Y)}{max(Y) - min(Y)} \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "\n",
        "You can verify this yourself if you wish, though it is not necessary.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}